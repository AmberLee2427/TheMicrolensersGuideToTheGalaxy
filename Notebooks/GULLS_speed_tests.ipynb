{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GULLS\n",
    "\n",
    "## Planet Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10000000 10000000 10000000]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import fcntl\n",
    "import time\n",
    "\n",
    "job_keys = ['A', 'B', 'C']\n",
    "rl = np.array([100000, 10000, 1000000]) # walkers\n",
    "nr = np.array([100, 1000, 10]) # steps\n",
    "print(rl*nr)\n",
    "gulls_data_dir = \"./Data/GULLS\"\n",
    "time_taken = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speeds Test Rsults for 10,000,000 Planets\n",
    "\n",
    "file arrangements:\n",
    "+ A: 100,000 entries in 100 files  = 10,000,000 planets\n",
    "+ B: 10,000 entries in 1000 files  = 10,000,000 planets\n",
    "+ C: 1,000,000 entries in 10 files = 10,000,000 planets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        joblib     pandas  npsavetxt       npy poolandnpsave\n",
      "A     0.522638  22.600857   17.75738  0.507046          5.45\n",
      "B     0.633548  23.629492   18.31468  0.787341           NaN\n",
      "C     0.566044  22.729151  17.804965  0.603358           NaN\n",
      "size    320 MB     780 MB       1 GB    320 MB          1 GB\n"
     ]
    }
   ],
   "source": [
    "# this needs to be run after the cells that follow\n",
    "\n",
    "# size of each run's output files (joblistA = joblistB = joblistC, etc.) manually entered\n",
    "joblib_times['size'] = '320 MB'\n",
    "pandas_times['size'] = '780 MB'  \n",
    "npsavetxt_times['size'] = '1 GB'  \n",
    "npy_times['size'] = '320 MB'\n",
    "\n",
    "poolandnpsave_times = {\n",
    "    'A': 5.45,\n",
    "    'B': np.nan,\n",
    "    'C': np.nan,\n",
    "    'size': '1 GB'\n",
    "}\n",
    "time_taken['poolandnpsave'] = poolandnpsave_times\n",
    "\n",
    "time_df = pd.DataFrame(time_taken)\n",
    "print(time_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The time taken appears mostly dependent on the save method chosen and scales by the total number of lines, not by how the files are broken up. The human readable outputs are about 40 times slower to produce than the machine readable outputs. The human readable files are about 3 times the size. How do the pearl scripts perform, by comparison? \\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to try parallelising the nf loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/malpas.1/Code/eLearning/TheMicrolensersGuideToTheGalaxy/Notebooks/uniform_draw_planet_arrays.py:80: RuntimeWarning: invalid value encountered in arccos\n",
      "  inc_array = 180 * np.where(rnd < 0.5, np.arccos(2 * rnd), -np.arccos(2 - 2 * rnd)) / pi\n",
      "/Users/malpas.1/Code/eLearning/TheMicrolensersGuideToTheGalaxy/Notebooks/uniform_draw_planet_arrays.py:80: RuntimeWarning: invalid value encountered in arccos\n",
      "  inc_array = 180 * np.where(rnd < 0.5, np.arccos(2 * rnd), -np.arccos(2 - 2 * rnd)) / pi\n",
      "/Users/malpas.1/Code/eLearning/TheMicrolensersGuideToTheGalaxy/Notebooks/uniform_draw_planet_arrays.py:80: RuntimeWarning: invalid value encountered in arccos\n",
      "  inc_array = 180 * np.where(rnd < 0.5, np.arccos(2 * rnd), -np.arccos(2 - 2 * rnd)) / pi\n",
      "/Users/malpas.1/Code/eLearning/TheMicrolensersGuideToTheGalaxy/Notebooks/uniform_draw_planet_arrays.py:80: RuntimeWarning: invalid value encountered in arccos\n",
      "  inc_array = 180 * np.where(rnd < 0.5, np.arccos(2 * rnd), -np.arccos(2 - 2 * rnd)) / pi\n",
      "/Users/malpas.1/Code/eLearning/TheMicrolensersGuideToTheGalaxy/Notebooks/uniform_draw_planet_arrays.py:80: RuntimeWarning: invalid value encountered in arccos\n",
      "  inc_array = 180 * np.where(rnd < 0.5, np.arccos(2 * rnd), -np.arccos(2 - 2 * rnd)) / pi\n",
      "/Users/malpas.1/Code/eLearning/TheMicrolensersGuideToTheGalaxy/Notebooks/uniform_draw_planet_arrays.py:80: RuntimeWarning: invalid value encountered in arccos\n",
      "  inc_array = 180 * np.where(rnd < 0.5, np.arccos(2 * rnd), -np.arccos(2 - 2 * rnd)) / pi\n",
      "/Users/malpas.1/Code/eLearning/TheMicrolensersGuideToTheGalaxy/Notebooks/uniform_draw_planet_arrays.py:80: RuntimeWarning: invalid value encountered in arccos\n",
      "  inc_array = 180 * np.where(rnd < 0.5, np.arccos(2 * rnd), -np.arccos(2 - 2 * rnd)) / pi\n",
      "/Users/malpas.1/Code/eLearning/TheMicrolensersGuideToTheGalaxy/Notebooks/uniform_draw_planet_arrays.py:80: RuntimeWarning: invalid value encountered in arccos\n",
      "  inc_array = 180 * np.where(rnd < 0.5, np.arccos(2 * rnd), -np.arccos(2 - 2 * rnd)) / pi\n",
      "Execution time: 5.45 seconds\n"
     ]
    }
   ],
   "source": [
    "!python uniform_draw_planet_arrays.py 100000 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speed Test Code Cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yk/2lp5vmnd6s778_4bh__0mvyc0000gp/T/ipykernel_93387/4170543892.py:57: RuntimeWarning: invalid value encountered in arccos\n",
      "  np.arccos(2.0 * rnd),\n",
      "/var/folders/yk/2lp5vmnd6s778_4bh__0mvyc0000gp/T/ipykernel_93387/4170543892.py:58: RuntimeWarning: invalid value encountered in arccos\n",
      "  -np.arccos(2.0 - 2.0 * rnd)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0.5487310886383057 seconds\n",
      "files: 100\n",
      "lines: 100000\n",
      "planets: 10000000\n",
      "Time taken: 0.9095323085784912 seconds\n",
      "files: 1000\n",
      "lines: 10000\n",
      "planets: 10000000\n",
      "Time taken: 0.648413896560669 seconds\n",
      "files: 10\n",
      "lines: 1000000\n",
      "planets: 10000000\n"
     ]
    }
   ],
   "source": [
    "# joblib\n",
    "\n",
    "# Constants\n",
    "mmin = math.log10(0.1)\n",
    "mmax = math.log10(100)\n",
    "rundes = \"kgriz_uf_ffp\"\n",
    "amin = math.log10(0.3)\n",
    "amax = amin + 2\n",
    "pi = math.pi\n",
    "\n",
    "\n",
    "def get_unique_indexes(master_list_file, n):\n",
    "    '''\n",
    "    This function exists so that multiplt versions of this script can be run at once without \n",
    "    overlapping file indexing. It reserves n indexes in the master list file and returns them.\n",
    "    '''\n",
    "    with open(master_list_file, 'a+') as f:\n",
    "        f.seek(0)\n",
    "        fcntl.flock(f, fcntl.LOCK_EX)\n",
    "        lines = f.readlines()\n",
    "        if lines:\n",
    "            start_index = int(lines[-1].strip()) + 1\n",
    "        else:\n",
    "            start_index = 0\n",
    "        end_index = start_index + n\n",
    "        for index in range(start_index, end_index):\n",
    "            f.write(f\"{index}\\n\")\n",
    "        fcntl.flock(f, fcntl.LOCK_UN)\n",
    "    return list(range(start_index, end_index))\n",
    "\n",
    "# Main logic\n",
    "def main(nf, nl):\n",
    "    dir_name = f\"{gulls_data_dir}/planets/{rundes}\"\n",
    "    if not os.path.exists(dir_name):\n",
    "        os.makedirs(dir_name)\n",
    "    base = f\"{dir_name}/{rundes}.planets\"\n",
    "    master_list_file = f\"{base}.master.lists\"\n",
    "\n",
    "    # Ensure the master list file exists\n",
    "    if not os.path.exists(master_list_file):\n",
    "        open(master_list_file, 'w').close()\n",
    "\n",
    "    # Reserve the next nf indexes\n",
    "    reserved_indexes = get_unique_indexes(master_list_file, nf)\n",
    "\n",
    "    for index in reserved_indexes:\n",
    "        pfile = f\"{base}.{index}.joblib\"\n",
    "        if os.path.exists(pfile):\n",
    "            print(f\"File {pfile} already exists. Skipping.\")\n",
    "        else:\n",
    "            combined_array = np.empty((nl, 4))\n",
    "            rnd = np.random.rand(nl)\n",
    "            \n",
    "            combined_array[:, 0] = 3.00374072e-6 * 10.0 ** (mmin + np.random.rand(nl) * (mmax - mmin))\n",
    "            combined_array[:, 1] = 10.0 ** (amin + (amax - amin) * np.random.rand(nl))\n",
    "            combined_array[:, 2] = 180.0 * np.where(rnd < 0.5, \n",
    "                                         np.arccos(2.0 * rnd), \n",
    "                                         -np.arccos(2.0 - 2.0 * rnd)\n",
    "                                         ) / pi\n",
    "            combined_array[:, 3] = 360.0 * np.random.rand(nl)\n",
    "            \n",
    "            # Saving data\n",
    "            joblib.dump(combined_array, pfile)\n",
    "\n",
    "joblib_times = {}\n",
    "for i, key in enumerate(job_keys):\n",
    "    start_time = time.time()\n",
    "    nl = rl[i]  \n",
    "    nf = nr[i]\n",
    "    main(nf, nl) \n",
    "    end_time = time.time()\n",
    "    joblib_times[key] = end_time - start_time\n",
    "    print(f\"Time taken: {end_time - start_time} seconds\")\n",
    "    print(f\"files: {nf}\")\n",
    "    print(f\"lines: {nl}\")\n",
    "    print(f\"planets: {nf*nl}\")\n",
    "\n",
    "time_taken['joblib'] = joblib_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yk/2lp5vmnd6s778_4bh__0mvyc0000gp/T/ipykernel_93387/343376780.py:54: RuntimeWarning: invalid value encountered in arccos\n",
      "  inc_array = 180 * np.where(rnd < 0.5, np.arccos(2 * rnd), -np.arccos(2 - 2 * rnd)) / pi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 22.60085678100586 seconds\n",
      "files: 100\n",
      "lines: 100000\n",
      "planets: 10000000\n",
      "Time taken: 23.629492044448853 seconds\n",
      "files: 1000\n",
      "lines: 10000\n",
      "planets: 10000000\n",
      "Time taken: 22.729151010513306 seconds\n",
      "files: 10\n",
      "lines: 1000000\n",
      "planets: 10000000\n"
     ]
    }
   ],
   "source": [
    "# pandas\n",
    "\n",
    "# Constants\n",
    "mmin = math.log10(0.1)\n",
    "mmax = math.log10(100)\n",
    "rundes = \"kgriz_uf_ffp\"\n",
    "amin = math.log10(0.3)\n",
    "amax = amin + 2\n",
    "pi = math.pi\n",
    "\n",
    "def get_unique_indexes(master_list_file, n):\n",
    "    '''\n",
    "    This function exists so that multiplt versions of this script can be run at once without \n",
    "    overlapping file indexing. It reserves n indexes in the master list file and returns them.\n",
    "    '''\n",
    "    with open(master_list_file, 'a+') as f:\n",
    "        f.seek(0)\n",
    "        fcntl.flock(f, fcntl.LOCK_EX)\n",
    "        lines = f.readlines()\n",
    "        if lines:\n",
    "            start_index = int(lines[-1].strip()) + 1\n",
    "        else:\n",
    "            start_index = 0\n",
    "        end_index = start_index + n\n",
    "        for index in range(start_index, end_index):\n",
    "            f.write(f\"{index}\\n\")\n",
    "        fcntl.flock(f, fcntl.LOCK_UN)\n",
    "    return list(range(start_index, end_index))\n",
    "\n",
    "# Main logic\n",
    "def main(nf, nl):\n",
    "    dir_name = f\"{gulls_data_dir}/planets/{rundes}\"\n",
    "    if not os.path.exists(dir_name):\n",
    "        os.makedirs(dir_name)\n",
    "    base = f\"{dir_name}/{rundes}.planets\"\n",
    "    master_list_file = f\"{base}.master.lists\"\n",
    "\n",
    "    # Ensure the master list file exists\n",
    "    if not os.path.exists(master_list_file):\n",
    "        open(master_list_file, 'w').close()\n",
    "\n",
    "    # Reserve the next nf indexes\n",
    "    reserved_indexes = get_unique_indexes(master_list_file, nf)\n",
    "\n",
    "    for index in reserved_indexes:\n",
    "        pfile = f\"{base}.{index}.csv\"\n",
    "        if os.path.exists(pfile):\n",
    "            print(f\"File {pfile} already exists. Skipping.\")\n",
    "        else:\n",
    "            # Generate arrays of size nl using NumPy\n",
    "            a_array = 10 ** (amin + (amax - amin) * np.random.rand(nl))\n",
    "            mass_array = 3.00374072e-6 * 10 ** (mmin + np.random.rand(nl) * (mmax - mmin))\n",
    "            rnd = np.random.rand(nl)\n",
    "            inc_array = 180 * np.where(rnd < 0.5, np.arccos(2 * rnd), -np.arccos(2 - 2 * rnd)) / pi\n",
    "            p_array = 360.0 * np.random.rand(nl)\n",
    "            \n",
    "            # Combine arrays into a single array\n",
    "            combined_array = np.empty((nl, 4))\n",
    "            combined_array[:, 0] = mass_array\n",
    "            combined_array[:, 1] = a_array\n",
    "            combined_array[:, 2] = inc_array\n",
    "            combined_array[:, 3] = p_array\n",
    "            \n",
    "            # Convert to pandas DataFrame\n",
    "            df = pd.DataFrame(combined_array, columns=['mass', 'a', 'inc', 'p'])\n",
    "            \n",
    "            # Save the DataFrame as a CSV file\n",
    "            df.to_csv(pfile, index=False)\n",
    "\n",
    "pandas_times = {}\n",
    "for i, key in enumerate(job_keys):\n",
    "    start_time = time.time()\n",
    "    nl = rl[i]  \n",
    "    nf = nr[i]\n",
    "    main(nf, nl) \n",
    "    end_time = time.time()\n",
    "    pandas_times[key] = end_time - start_time\n",
    "    print(f\"Time taken: {end_time - start_time} seconds\")\n",
    "    print(f\"files: {nf}\")\n",
    "    print(f\"lines: {nl}\")\n",
    "    print(f\"planets: {nf*nl}\")\n",
    "\n",
    "time_taken['pandas'] = pandas_times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yk/2lp5vmnd6s778_4bh__0mvyc0000gp/T/ipykernel_93387/3012592641.py:54: RuntimeWarning: invalid value encountered in arccos\n",
      "  inc_array = 180 * np.where(rnd < 0.5, np.arccos(2 * rnd), -np.arccos(2 - 2 * rnd)) / pi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 17.75737977027893 seconds\n",
      "files: 100\n",
      "lines: 100000\n",
      "planets: 10000000\n",
      "Time taken: 18.314679861068726 seconds\n",
      "files: 1000\n",
      "lines: 10000\n",
      "planets: 10000000\n",
      "Time taken: 17.804965257644653 seconds\n",
      "files: 10\n",
      "lines: 1000000\n",
      "planets: 10000000\n"
     ]
    }
   ],
   "source": [
    "# numpy.savetext\n",
    "\n",
    "# Constants\n",
    "mmin = math.log10(0.1)\n",
    "mmax = math.log10(100)\n",
    "rundes = \"kgriz_uf_ffp\"\n",
    "amin = math.log10(0.3)\n",
    "amax = amin + 2\n",
    "pi = math.pi\n",
    "\n",
    "def get_unique_indexes(master_list_file, n):\n",
    "    '''\n",
    "    This function exists so that multiplt versions of this script can be run at once without \n",
    "    overlapping file indexing. It reserves n indexes in the master list file and returns them.\n",
    "    '''\n",
    "    with open(master_list_file, 'a+') as f:\n",
    "        f.seek(0)\n",
    "        fcntl.flock(f, fcntl.LOCK_EX)\n",
    "        lines = f.readlines()\n",
    "        if lines:\n",
    "            start_index = int(lines[-1].strip()) + 1\n",
    "        else:\n",
    "            start_index = 0\n",
    "        end_index = start_index + n\n",
    "        for index in range(start_index, end_index):\n",
    "            f.write(f\"{index}\\n\")\n",
    "        fcntl.flock(f, fcntl.LOCK_UN)\n",
    "    return list(range(start_index, end_index))\n",
    "\n",
    "# Main logic\n",
    "def main(nf, nl):\n",
    "    dir_name = f\"{gulls_data_dir}/planets/{rundes}\"\n",
    "    if not os.path.exists(dir_name):\n",
    "        os.makedirs(dir_name)\n",
    "    base = f\"{dir_name}/{rundes}.planets\"\n",
    "    master_list_file = f\"{base}.master.lists\"\n",
    "\n",
    "    # Ensure the master list file exists\n",
    "    if not os.path.exists(master_list_file):\n",
    "        open(master_list_file, 'w').close()\n",
    "\n",
    "    # Reserve the next nf indexes\n",
    "    reserved_indexes = get_unique_indexes(master_list_file, nf)\n",
    "\n",
    "    for index in reserved_indexes:\n",
    "        pfile = f\"{base}.{index}.csv\"\n",
    "        if os.path.exists(pfile):\n",
    "            print(f\"File {pfile} already exists. Skipping.\")\n",
    "        else:\n",
    "            # Generate arrays of size nl using NumPy\n",
    "            a_array = 10 ** (amin + (amax - amin) * np.random.rand(nl))\n",
    "            mass_array = 3.00374072e-6 * 10 ** (mmin + np.random.rand(nl) * (mmax - mmin))\n",
    "            rnd = np.random.rand(nl)\n",
    "            inc_array = 180 * np.where(rnd < 0.5, np.arccos(2 * rnd), -np.arccos(2 - 2 * rnd)) / pi\n",
    "            p_array = 360.0 * np.random.rand(nl)\n",
    "            \n",
    "            # Combine arrays into a single array\n",
    "            combined_array = np.empty((nl, 4))\n",
    "            combined_array[:, 0] = mass_array\n",
    "            combined_array[:, 1] = a_array\n",
    "            combined_array[:, 2] = inc_array\n",
    "            combined_array[:, 3] = p_array\n",
    "            \n",
    "            # Save the combined array as a CSV file\n",
    "            np.savetxt(pfile, combined_array, delimiter=',', header='mass,a,inc,p', comments='')\n",
    "\n",
    "npsavetxt_times = {}\n",
    "for i, key in enumerate(job_keys):\n",
    "    start_time = time.time()\n",
    "    nl = rl[i]  \n",
    "    nf = nr[i]\n",
    "    main(nf, nl) \n",
    "    end_time = time.time()\n",
    "    npsavetxt_times[key] = end_time - start_time\n",
    "    print(f\"Time taken: {end_time - start_time} seconds\")\n",
    "    print(f\"files: {nf}\")\n",
    "    print(f\"lines: {nl}\")\n",
    "    print(f\"planets: {nf*nl}\")\n",
    "\n",
    "time_taken['npsavetxt'] = npsavetxt_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yk/2lp5vmnd6s778_4bh__0mvyc0000gp/T/ipykernel_93387/558777606.py:54: RuntimeWarning: invalid value encountered in arccos\n",
      "  inc_array = 180 * np.where(rnd < 0.5, np.arccos(2 * rnd), -np.arccos(2 - 2 * rnd)) / pi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0.5070459842681885 seconds\n",
      "files: 100\n",
      "lines: 100000\n",
      "planets: 10000000\n",
      "Time taken: 0.7873411178588867 seconds\n",
      "files: 1000\n",
      "lines: 10000\n",
      "planets: 10000000\n",
      "Time taken: 0.6033580303192139 seconds\n",
      "files: 10\n",
      "lines: 1000000\n",
      "planets: 10000000\n"
     ]
    }
   ],
   "source": [
    "# numpy\n",
    "\n",
    "# Constants\n",
    "mmin = math.log10(0.1)\n",
    "mmax = math.log10(100)\n",
    "rundes = \"kgriz_uf_ffp\"\n",
    "amin = math.log10(0.3)\n",
    "amax = amin + 2\n",
    "pi = math.pi\n",
    "\n",
    "def get_unique_indexes(master_list_file, n):\n",
    "    '''\n",
    "    This function exists so that multiplt versions of this script can be run at once without \n",
    "    overlapping file indexing. It reserves n indexes in the master list file and returns them.\n",
    "    '''\n",
    "    with open(master_list_file, 'a+') as f:\n",
    "        f.seek(0)\n",
    "        fcntl.flock(f, fcntl.LOCK_EX)\n",
    "        lines = f.readlines()\n",
    "        if lines:\n",
    "            start_index = int(lines[-1].strip()) + 1\n",
    "        else:\n",
    "            start_index = 0\n",
    "        end_index = start_index + n\n",
    "        for index in range(start_index, end_index):\n",
    "            f.write(f\"{index}\\n\")\n",
    "        fcntl.flock(f, fcntl.LOCK_UN)\n",
    "    return list(range(start_index, end_index))\n",
    "\n",
    "# Main logic\n",
    "def main(nf, nl):\n",
    "    dir_name = f\"{gulls_data_dir}/planets/{rundes}\"\n",
    "    if not os.path.exists(dir_name):\n",
    "        os.makedirs(dir_name)\n",
    "    base = f\"{dir_name}/{rundes}.planets\"\n",
    "    master_list_file = f\"{base}.master.lists\"\n",
    "\n",
    "    # Ensure the master list file exists\n",
    "    if not os.path.exists(master_list_file):\n",
    "        open(master_list_file, 'w').close()\n",
    "\n",
    "    # Reserve the next nf indexes\n",
    "    reserved_indexes = get_unique_indexes(master_list_file, nf)\n",
    "\n",
    "    for index in reserved_indexes:\n",
    "        pfile = f\"{base}.{index}.npy\"\n",
    "        if os.path.exists(pfile):\n",
    "            print(f\"File {pfile} already exists. Skipping.\")\n",
    "        else:\n",
    "            # Generate arrays of size nl using NumPy\n",
    "            a_array = 10 ** (amin + (amax - amin) * np.random.rand(nl))\n",
    "            mass_array = 3.00374072e-6 * 10 ** (mmin + np.random.rand(nl) * (mmax - mmin))\n",
    "            rnd = np.random.rand(nl)\n",
    "            inc_array = 180 * np.where(rnd < 0.5, np.arccos(2 * rnd), -np.arccos(2 - 2 * rnd)) / pi\n",
    "            p_array = 360.0 * np.random.rand(nl)\n",
    "            \n",
    "            # Combine arrays into a single array\n",
    "            combined_array = np.empty((nl, 4))\n",
    "            combined_array[:, 0] = mass_array\n",
    "            combined_array[:, 1] = a_array\n",
    "            combined_array[:, 2] = inc_array\n",
    "            combined_array[:, 3] = p_array\n",
    "            \n",
    "            # Save the combined array as a CSV file\n",
    "            np.save(pfile, combined_array)\n",
    "\n",
    "npy_times = {}\n",
    "for i, key in enumerate(job_keys):\n",
    "    start_time = time.time()\n",
    "    nl = rl[i]  \n",
    "    nf = nr[i]\n",
    "    main(nf, nl) \n",
    "    end_time = time.time()\n",
    "    npy_times[key] = end_time - start_time\n",
    "    print(f\"Time taken: {end_time - start_time} seconds\")\n",
    "    print(f\"files: {nf}\")\n",
    "    print(f\"lines: {nl}\")\n",
    "    print(f\"planets: {nf*nl}\")\n",
    "\n",
    "time_taken['npy'] = npy_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pearl\n",
    "\n",
    "import subprocess\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Define the path to your Perl script\n",
    "perl_script_path = 'Assets/scriptA.pl'  # I don't have this script working\n",
    "\n",
    "# Run the Perl script\n",
    "result = subprocess.run(['perl', perl_script_path], capture_output=True, text=True, esult = subprocess.run(['perl', perl_script_path], stdout=stdout_log, stderr=stderr_log)\n",
    "\n",
    "end_time = time.time()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TheGuide",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
