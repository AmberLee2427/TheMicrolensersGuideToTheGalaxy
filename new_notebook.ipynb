{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6af0463",
   "metadata": {},
   "source": [
    "*This is a brief notebook, but it is heavily reliant on the concepts covered in the [Single Lens](SingleLens.ipynb) notebook. If you have not completed that notebook, perhaps it would be best if you did that and then came back.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3e419d",
   "metadata": {},
   "source": [
    "If you haven't already done so, install MulensModel before continuing with this notebook:\n",
    "```bash\n",
    "pip install MulensModel\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4caa2ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# package imports (SHIFT + ENTER to run)\n",
    "import numpy as np\n",
    "import emcee\n",
    "import MulensModel as mm\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing as mp\n",
    "from IPython.display import display, clear_output\n",
    "from typing import List, Tuple, Optional, Union\n",
    "\n",
    "# dev note: replace emcee with dynesty?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b96d6c0",
   "metadata": {},
   "source": [
    "# The binary source model\n",
    "\n",
    "Events matching a one-lens, two-sources model typically have lightcurves with smooth non-Paczynski shapes, such as the one in [Jung et al. (2017)](https://ui.adsabs.harvard.edu/abs/2017AJ....153..129J), [Figure 5](https://www.astroexplorer.org/details/ajaa5d07f5), which is shown below (event OGLE-2016-BLG-0733). They are, in effect, two distinct Paczynski curves on top of each other; they do not create \"sharp\" perturbations from the primary Paczynski curve, like the binary-lens models typically do.\n",
    "\n",
    "<style>\n",
    "    table {\n",
    "        margin-left: auto;\n",
    "        margin-right: auto;\n",
    "        width: 95%;\n",
    "        text-align: center;\n",
    "    }\n",
    "</style>\n",
    "\n",
    "| ![Jung 2017 Figure 5](./Assets/Jung2017-F5.jpg) | ![Jung 2017 Figure 3](./Assets/Jung2017-F3.jpg) |\n",
    "| :-: | :-: |\n",
    "| [Reproduction of [Jung et al. (2017)](https://ui.adsabs.harvard.edu/abs/2017AJ....153..129J), [Figure 5](https://www.astroexplorer.org/details/ajaa5d07f5)] Geometry and lightcurve of the binary-source model. *Top:* The upper panel shows the geometry of the binary-source model. Two straight lines with arrows are the source trajectories of individual source stars. The lens is located at the origin (marked by M), and the dotted circle is the angular Einstein ring. The red and blue filled circles represent the individual source positions at $\\rm{HJD}'=7497$. Lengths are normalised by the Einstein radius. *Bottom:* The lower panel shows the enlarged view of the anomaly region. The two curves with different colours are best-fit binary-source models for $RI$ and $I$ passbands. The inset shows a zoom of the anomaly near $\\rm{HJD}'\\sim7501.4$. We note that, although we only use the $V$-band data for determining the source type, we also present the $V$-band model lightcurve to compare the colour change between passbands. | [Reproduction of [Jung et al. (2017)](https://ui.adsabs.harvard.edu/abs/2017AJ....153..129J), [Figure 3](https://www.astroexplorer.org/details/ajaa5d07f3)] Geometry and lightcurve of the binary lens model. *Top:* The upper panel shows the geometry of the binary lens model. The straight line with an arrow is the source trajectory, red closed concave curves represent the caustics, and blue filled circles (marked by $M_1$ and $M_2$) are the binary lens components. All length scales are normalised by the Einstein radius. The inset shows the general view and the major panel shows the enlarged view corresponding to the lightcurve of the lower panel. The open circle on the source trajectory is the source position at the time of observation whose size represents the source size. *Bottom:* The lower panel shows the enlarged view of the anomaly region. The inset shows a zoom of the lightcurve near $\\rm{HJD}'\\sim7501.4$. The curve superposed on the data is the best-fit binary lens model. |\n",
    "\n",
    "The magnification model has the same parameterisation as the single lens model, except the flux model is a sum of two single-source magnifications multiplied by the flux of the source they are lensing:\n",
    "$$ \\mathbf{F}=\\mathbf{A_1}F_{\\rm S1}+\\mathbf{A_2}F_{\\rm S2}+F_{\\rm B}, $$\n",
    "where $\\mathbf{A_1}$ and $F_{\\rm S1}$ are the primary-source magnification model and flux, $\\mathbf{A_2}$ and $F_{\\rm S2}$ are the secondary-source magnification model and flux, $F_{\\rm B}$ is the blend flux, and the models $\\mathbf{A_1}$ and $\\mathbf{A_2}$ share the same physical lens parameters $(D_{\\rm L},\\,M_{\\rm L})$.\n",
    "\n",
    "We can see the model in practice in the code cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a014403e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simulated binary source event\n",
    "\n",
    "t01, u01 = 6100., 0.2  # primary source model parameters\n",
    "t02, u02 = 6140., 0.2  # secondary source model parameters\n",
    "t_E = 25.   # tE is not necessarily the same, due to orbital motion of the lens system, but we would expect \n",
    "            # tE to be mostly due to the relative propermotion of the lens and source systems.\n",
    "flux1, flux_ratio, blend_flux = 100., 0.1, 50.\n",
    "n = 500  # number of data points\n",
    "time = np.linspace(6000., 6300., n)  # \"data\" epochs\n",
    "N = 1000  # model plotting precision\n",
    "T = np.linspace(6000., 6300., N)  # model time array\n",
    "\n",
    "# building the individual magnification models for each source star\n",
    "model1 = mm.Model({'t_0': t01, 'u_0': u01, 't_E': t_E})\n",
    "A1 = model1.get_magnification(time)\n",
    "model2 = mm.Model({'t_0': t02, 'u_0': u02, 't_E': t_E})\n",
    "A2 = model2.get_magnification(time)\n",
    "\n",
    "flux = A1 * flux1 + A2 * flux1*flux_ratio + blend_flux\n",
    "flux_err = 3.0 *(np.abs(5.0 + np.random.normal(size=n)))  # flux uncertainties with mu=15 and std=3\n",
    "error = flux_err * np.random.normal(size=n)     # offset the \"meaasurments\" by an amount that is dependent    \n",
    "flux += error                                   # on the uncertainty\n",
    "data = [time, flux, flux_err]\n",
    "\n",
    "my_dataset = mm.MulensData(data, phot_fmt='flux')\n",
    "\n",
    "plt.close(1)\n",
    "plt.figure(1)\n",
    "\n",
    "# Plot the data\n",
    "plt.errorbar(time, flux, yerr=flux_err, \n",
    "             fmt='x', \n",
    "             ecolor='k', \n",
    "             capsize=1, \n",
    "             color='k', \n",
    "             alpha=0.6, \n",
    "             zorder=0,\n",
    "             label='simulated data'\n",
    "             )\n",
    "# Plot the model\n",
    "F = model1.get_magnification(T) * flux1 + model2.get_magnification(T) * flux1*flux_ratio + blend_flux\n",
    "plt.plot(T, F, \n",
    "         color='r', \n",
    "         linestyle='-', \n",
    "         lw=1, \n",
    "         zorder=1, \n",
    "         label='1L2S model'\n",
    "         )\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(r'HJD (days)')\n",
    "plt.ylabel(r'flux')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ebce3c",
   "metadata": {},
   "source": [
    "The measure of how far the data are from the model solution, scaled by the data uncertainties ($\\chi^2$), is calculated using \n",
    "$$ \\chi^2 = \\sum\\limits_i \\frac{\\left(F_i - x_i\\right)^2} {\\sigma_i^2}. $$ \n",
    "$\\chi^2$ quantifies how likely a parameter set is to have generated the observed data, for a given model.\n",
    "\n",
    "Similar to the procedure in the [Single Lens](SingleLens.ipynb) notebook, the maximum likelihood solution $(F_{\\rm S1}, F_{\\rm S2}, F_{\\rm B})$ can therefore be found by solving for the minima of this function. As in the previous section, the minima occurs where the partial derivatives of the $\\chi^2$ function are 0;\n",
    "$$\n",
    "    \\frac{\\partial\\chi^2}{\\partial F_{\\rm S1}} = 0, \n",
    "    \\frac{\\partial\\chi^2}{\\partial F_{\\rm S2}} = 0, \n",
    "    \\frac{\\partial\\chi^2}{\\partial F_{\\rm B}} = 0.\n",
    "$$\n",
    "This linear regression problem can be written in the form\n",
    "$$\n",
    "\\begin{matrix}\n",
    "    \\begin{bmatrix}\n",
    "        \\sum\\limits_{i}\\frac{A_{1,i}^{2}}{\\sigma_{i}^{2}} & \n",
    "        \\sum\\limits_{i}\\frac{A_{1,i}A_{2,i}}{\\sigma_{i}^{2}} &\n",
    "        \\sum\\limits_{i}\\frac{A_{1,i}}{\\sigma_{i}^{2}} \\\\ \n",
    "        \\sum\\limits_{i}\\frac{A_{1,i}A_{2,i}}{\\sigma_{i}^{2}} &\n",
    "        \\sum\\limits_{i}\\frac{A_{2,i}^{2}}{\\sigma_{i}^{2}} & \n",
    "        \\sum\\limits_{i}\\frac{A_{2,i}}{\\sigma_{i}^{2}} \\\\ \n",
    "        \\sum\\limits_{i}\\frac{A_{1,i}}{\\sigma_{i}^{2}} &\n",
    "        \\sum\\limits_{i}\\frac{A_{2,i}}{\\sigma_{i}^{2}} &\n",
    "        \\sum\\limits_{i}\\frac{1}{\\sigma_{i}^{2}}\n",
    "    \\end{bmatrix}\n",
    "    & \\times &\n",
    "    \\begin{bmatrix}\n",
    "        F_{\\rm S1} \\\\ \n",
    "        F_{\\rm S2} \\\\ \n",
    "        F_{\\rm B}\n",
    "    \\end{bmatrix}\n",
    "    & = &\n",
    "    \\begin{bmatrix}\n",
    "        \\sum\\limits_{i}\\frac{A_{1,i}x_{i}}{\\sigma_{i}^{2}} \\\\ \n",
    "        \\sum\\limits_{i}\\frac{A_{2,i}x_{i}}{\\sigma_{i}^{2}} \\\\ \n",
    "        \\sum\\limits_{i}\\frac{x_{i}}{\\sigma_{i}^{2}}\n",
    "    \\end{bmatrix}\n",
    "    \\\\\n",
    "    \\mathbf{B} &\\times& \\mathbf{\\Theta} &=& \\mathbf{C},\n",
    "\\end{matrix}\n",
    "$$\n",
    "\n",
    "which is solved following as follows:\n",
    "$$ \\mathbf{\\Theta} = \\mathbf{B}^{-1} \\mathbf{C} = \\frac{adj\\,\\mathbf{B}}{\\det\\mathbf{B}} \\cdot \\mathbf{C}. $$\n",
    "\n",
    "<div style=\"background-color:#e0e0e0; \n",
    "    border-left: 8px solid #808080; \n",
    "    padding: 10px 0 10px 20px; \n",
    "    margin: 20px 5px; \n",
    "    box-sizing: border-box\"> <a href=\"./Exercises/BinarySourceE1.txt\">\n",
    "    <h2 style=\"color: #808080; font-size: 24px;\">Exercise 1</h2>\n",
    "    </a>\n",
    "    <p style=\"margin: 0 20px;\">Use linear regression to determine the flux of the primary source, secondary source, and blend stars. Did you get out something similar to what you put in?</p>\n",
    "    <br>\n",
    "    <p style=\"margin: 0 20px;\"><i>You may want to consider using functions from the numpy.linalg module.</i></p>\n",
    "    <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06bfde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# objective function\n",
    "def binary_source_chi2(theta: np.ndarray, \n",
    "                       model1: mm.Model, \n",
    "                       model2: mm.Model, \n",
    "                       data: List, \n",
    "                       verbose: Optional[bool] = False,\n",
    "                       return_fluxes: Optional[bool] = False\n",
    "                       ) -> float:\n",
    "    \"\"\"\n",
    "    chi2 function for a binary-source, single-lens, microlensing model.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    theta : np.ndarray\n",
    "        Array of model parameters being fit.\n",
    "    model1 : mm.Model\n",
    "        Primary source model.\n",
    "    model2 : mm.Model\n",
    "        Secondary source model.\n",
    "    data : list\n",
    "        List of data arrays.\n",
    "    verbose : bool, optional\n",
    "        Default is False.\n",
    "        Print the primary source flux, secondary source flux, and blend flux.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The chi2 value.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The model parameters are unpacked from theta and set to the model1 and model2 parameters.\n",
    "    model1 and model2 are MulensModel.Model objects; see MulensModel documentation \n",
    "    (https://rpoleski.github.io/MulensModel/) for more information.\n",
    "    \"\"\"\n",
    "    #unpack the data\n",
    "    t, flux, flux_err = data\n",
    "\n",
    "    # model parameters being fit\n",
    "    labels = ['t_0', 'u_0', 't_E']\n",
    "\n",
    "    # change the values of model.parameters to those in theta.\n",
    "    theta1 = theta[:3]\n",
    "    theta2 = theta[3:]\n",
    "    for (label, value1, value2) in zip(labels, theta1, theta2):\n",
    "        setattr(model1.parameters, label, value1)\n",
    "        setattr(model2.parameters, label, value2)\n",
    "    \n",
    "    # calculate the model magnification for each source\n",
    "    A1 = model1.get_magnification(t)\n",
    "    A2 = model2.get_magnification(t)\n",
    "\n",
    "    ######################\n",
    "    # EXERCISE: BinarySourceE1.txt\n",
    "    #---------------------\n",
    "    # build the matricies for the linear algebra\n",
    "    C = np.array([np.sum(A1 * flux * flux_err**-2), np.sum(A2 * flux * flux_err**-2), np.sum(flux * flux_err**-2)])\n",
    "    B = np.array([[np.sum(A1**2 * flux_err**-2), np.sum(A1 * A2 * flux_err**-2), np.sum(A1 * flux_err**-2)],\n",
    "                  [np.sum(A1 * A2 * flux_err**-2), np.sum(A2**2 * flux_err**-2), np.sum(A2 * flux_err**-2)],\n",
    "                  [np.sum(A1 * flux_err**-2), np.sum(A2 * flux_err**-2), np.sum(flux_err**-2)]])\n",
    "    \n",
    "    # calculate the flux components\n",
    "    Theta = np.linalg.solve(B, C)  # ax=b <- B x Theta = C\n",
    "    FS1, FS2, FB = Theta # primary source flux, secondary source flux, and blend flux\n",
    "    ######################\n",
    "\n",
    "    # print the flux parameters\n",
    "    if verbose:\n",
    "        print(f\"Primary source flux: {FS1}\")\n",
    "        print(f\"Secondary source flux: {FS2}\")\n",
    "        print(f\"Blend flux: {FB}\")\n",
    "\n",
    "    # calculate the model flux\n",
    "    model_flux = A1 * FS1 + A2 * FS2 + FB\n",
    "    chi2 = np.sum(((flux - model_flux) / flux_err)**2)\n",
    "\n",
    "    # In case something goes wrong with the linear algebra\n",
    "    if np.isnan(chi2) or np.isinf(chi2):\n",
    "        print(f\"NaN or inf encountered in chi2 calculation: theta={theta}, chi2={chi2}\")\n",
    "        return 1e16\n",
    "\n",
    "    if return_fluxes:\n",
    "        return chi2, FS1, FS2, FB\n",
    "    else:\n",
    "        return chi2\n",
    "\n",
    "\n",
    "# generative model parameters\n",
    "t01, u01 = 6100., 0.2\n",
    "t02, u02 = 6140., 0.2\n",
    "t_E = 25.\n",
    "theta = np.array([t01, u01, t_E, t02, u02, t_E])\n",
    "\n",
    "# initial chi2 value (will print the fluxes)\n",
    "chi2 = binary_source_chi2(theta, model1, model2, data, verbose=True)\n",
    "\n",
    "# generative fluxes\n",
    "# source 2 flux used to generate the data\n",
    "flux2 = flux1 * flux_ratio\n",
    "print('\\nprimary source flux used to generate the data:', flux1)\n",
    "print('secondary source flux used to generate the data:', flux2)\n",
    "print('blend flux used to generate the data:', blend_flux)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4f1e57",
   "metadata": {},
   "source": [
    "The noise we generated in the light curve should mean that, even though we used the \"true\" magnification-model parameters, the flux values we retrieve are not exactly the same as those we used to generate the lightcurve. But they should be close (i.e. within a few flux units). If you got values that are wildly different something has gone wrong. It could be a fluke, so start be regenerating your noisy data. If that doesn't fix the problem you will need to take another look at your $\\chi^2$ function (Exercise 1).\n",
    "\n",
    "<div style=\"background-color:#e0e0e0; \n",
    "    border-left: 8px solid #808080; \n",
    "    padding: 10px 0 10px 20px; \n",
    "    margin: 20px 5px; \n",
    "    box-sizing: border-box\"> <a href=\"./Exercises/BinarySourceE2.txt\">\n",
    "    <h2 style=\"color: #808080; font-size: 24px;\">Exercise 2</h2>\n",
    "    </a>\n",
    "    <p style=\"margin: 0 20px;\">Make an initial guess at the parameters for this model.</p>\n",
    "    <br>\n",
    "    <p style=\"margin: 0 20px;\"><i>I know, we know them. Pretend we don't, okay.</i></p>\n",
    "    <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c871f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "# EXERCISE: BinarySourceE2.txt\n",
    "#---------------------\n",
    "# initial guess\n",
    "t01 = 6100\n",
    "t02 = 6140\n",
    "u01 = 0.2\n",
    "u02 = 0.3\n",
    "tE1 = 25\n",
    "tE2 = 25\n",
    "\n",
    "# fitting the model\n",
    "theta0 = [t01, u01, tE1, t02, u02, tE2]\n",
    "######################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f81a6e",
   "metadata": {},
   "source": [
    "Next we are going to try fitting the data. Even though the likelihood space for a binary-source model should be reasonably well behaved, we will fit this simulated event using MCMC (emcee), because we want to take a look at the posteriors from the fit, so that we can understand if there are any degeneracies between magnification-model parameters. We can use emcee to both fit and collect our posterior samples. \n",
    "\n",
    "> If that all sounded like a forgein language to you, you might need to check-out, or revist, the [Modelling](Modelling.ipynb) notebook. \n",
    "\n",
    "<div style=\"background-color:#e0e0e0; \n",
    "    border-left: 8px solid #808080; \n",
    "    padding: 10px 0 10px 20px; \n",
    "    margin: 20px 5px; \n",
    "    box-sizing: border-box\"> <a href=\"./Exercises/BinarySourceE3.txt\">\n",
    "    <h2 style=\"color: #808080; font-size: 24px;\">Exercise 3</h2>\n",
    "    </a>\n",
    "    <p style=\"margin: 0 20px;\">Apply some reasonable bounds on the magnification-model parameters (<i>theta</i>).</p>\n",
    "    <br>\n",
    "    <p style=\"margin: 0 20px;\"><i>Replace \"True\" with your conditions for what constitutes unresonable model-parameter values.</i></p>\n",
    "    <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e28e766",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ln_prob(theta: np.ndarray, model1, model2, data) -> float:\n",
    "    \"\"\"log probability\"\"\"\n",
    "\n",
    "    lp = 0.0\n",
    "\n",
    "    ######################\n",
    "    # EXERCISE: BinarySourceE3.txt\n",
    "    #---------------------\n",
    "    # priors                         # replace True with conditions\n",
    "\n",
    "    # add a constraint on tEs with a 1 sig deltatE of 5 days\n",
    "    lp += -(theta[2]-theta[5])**2/5**2   # this discourages the tEs from being too different\n",
    "\n",
    "    if np.any(np.array(theta) < 0) or theta[0] > theta[3] or theta[0] < 6000 or theta[3] < 6000 or theta[0] > 6300 or theta[3] > 6300:\n",
    "        return -1e16\n",
    "    \n",
    "    elif (theta[2]-theta[5])**2 > 20**2:  # max 20 days difference\n",
    "        return -1e16\n",
    "    ######################\n",
    "\n",
    "    else: # the proposed parameters values are reasonable\n",
    "\n",
    "        ######################\n",
    "        # EXERCISE: BinarySourceE7.txt\n",
    "    #---------------------\n",
    "    # priors                         # replace True with conditions\n",
    "\n",
    "    # add a constraint on tEs with a 1 sig deltatE of 5 days\n",
    "    lp += -(theta[2]-theta[5])**2/5**2   # this discourages the tEs from being too different\n",
    "\n",
    "    if np.any(np.array(theta) < 0) or theta[0] > theta[3] or theta[0] < 6000 or theta[3] < 6000 or theta[0] > 6300 or theta[3] > 6300:\n",
    "        return -1e16\n",
    "    \n",
    "    elif (theta[2]-theta[5])**2 > 20**2:  # max 20 days difference\n",
    "        return -1e16\n",
    "    ######################\n",
    "\n",
    "        # return the log probability\n",
    "        return -0.5 * chi2 + lp\n",
    "\n",
    "# starting lnL\n",
    "lnP = ln_prob(theta0, model1, model2, data)\n",
    "print('initial log probability:', lnP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b83258c",
   "metadata": {},
   "source": [
    "This model is pretty simple. It shouldn't take too long to converge; 1000 steps should be more than enough. \n",
    "\n",
    "<div style=\"background-color:#e0e0e0; \n",
    "    border-left: 8px solid #808080; \n",
    "    padding: 10px 0 10px 20px; \n",
    "    margin: 20px 5px; \n",
    "    box-sizing: border-box\"> <a href=\"./Exercises/BinarySourceE4.txt\">\n",
    "    <h2 style=\"color: #808080; font-size: 24px;\">Exercise 4</h2>\n",
    "    </a>\n",
    "    <p style=\"margin: 0 20px;\">Set up the emcee sample by choosing the fitting parameters you would like to use.</p>\n",
    "    <br>\n",
    "    <p style=\"margin: 0 20px;\"><i>Note. there is only one correct value for ndim, but the other parameters are more nebulous.</i></p>\n",
    "    <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6c58dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# emcee parameters\n",
    "nsteps = 1000\n",
    "######################\n",
    "# EXERCISE: BinarySourceE4.txt\n",
    "#---------------------\n",
    "nwalkers = 100\n",
    "ndim = len(theta0)\n",
    "steps_between_plot_updates = 100\n",
    "######################\n",
    "\n",
    "# Set up the sampler\n",
    "sampler = emcee.EnsembleSampler(nwalkers, ndim, ln_prob, \n",
    "                                args=[model1, model2, data])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40704d4f",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#e0e0e0; \n",
    "    border-left: 8px solid #808080; \n",
    "    padding: 10px 0 10px 20px; \n",
    "    margin: 20px 5px; \n",
    "    box-sizing: border-box\"> <a href=\"./Exercises/BinarySourceE5.txt\">\n",
    "    <h2 style=\"color: #808080; font-size: 24px;\">Exercise 5</h2>\n",
    "    </a>\n",
    "    <p style=\"margin: 0 20px;\">Create an initial state for you walkers.</p>\n",
    "    <br>\n",
    "    <p style=\"margin: 0 20px;\"><i>Note. These should be \"random\" values, close to your initial guess; the walkers should start in a hyper-dimensional ball in parameter space, about the inital guess. You might want to consider the np.random.randn function.</i></p>\n",
    "    <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058dd609",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "# EXERCISE: BinarySourceE5.txt\n",
    "#---------------------\n",
    "# Initialize the walkers\n",
    "initial_pos = theta0 + 1e-6 * np.random.randn(nwalkers, ndim)\n",
    "######################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683f9f79",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#e0e0e0; \n",
    "    border-left: 8px solid #808080; \n",
    "    padding: 10px 0 10px 20px; \n",
    "    margin: 20px 5px; \n",
    "    box-sizing: border-box\"> <a href=\"./Exercises/BinarySourceE6.txt\">\n",
    "    <h2 style=\"color: #808080; font-size: 24px;\">Exercise 6</h2>\n",
    "    </a>\n",
    "    <p style=\"margin: 0 20px;\">Run the sampler. Do you notice anything strange about any of the chains?</p>\n",
    "    <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d46a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to update the plot\n",
    "def update_plot(sampler, nwalkers, fig, axes):\n",
    "    ylabels = [r'$t_{0,1}$', r'$u_{0,1}$', r'$t_{\\rm{E},1}$', \n",
    "               r'$t_{0,2}$', r'$u_{0,2}$', r'$t_{\\rm{E},2}$',\n",
    "               r'$\\ln{P}$']\n",
    "    for j in range(ndim):\n",
    "        axes[j].clear()\n",
    "        for i in range(nwalkers):\n",
    "            axes[j].plot(sampler.chain[i, :, j], 'k', alpha=0.1)\n",
    "        axes[j].set_ylabel(ylabels[j])\n",
    "    \n",
    "    axes[ndim].clear()\n",
    "    for i in range(nwalkers):\n",
    "        axes[ndim].plot(sampler.lnprobability[i], 'r', alpha=0.1)\n",
    "    axes[ndim].set_ylabel(ylabels[ndim])\n",
    "    axes[ndim].set_xlabel('step')\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    display(fig)\n",
    "    fig.canvas.draw()\n",
    "    fig.canvas.flush_events()\n",
    "\n",
    "def run_emcee(sampler: emcee.EnsembleSampler,\n",
    "              initial_pos: np.ndarray,\n",
    "              nsteps: int,\n",
    "              steps_between_plot_updates: int,\n",
    "              nwalkers: int,\n",
    "              ndim: int,\n",
    "              verbose: Optional[bool] = True\n",
    "              ) -> Tuple[emcee.EnsembleSampler, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Run the emcee sampler and update the plot.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sampler : emcee.EnsembleSampler\n",
    "        The sampler object.\n",
    "    initial_pos : np.ndarray\n",
    "        The initial position of the walkers.\n",
    "    nsteps : int\n",
    "        The number of steps to run the sampler.\n",
    "    steps_between_plot_updates : int\n",
    "        The number of steps between plot updates.\n",
    "    nwalkers : int\n",
    "        The number of walkers.\n",
    "    ndim : int\n",
    "        The number of dimensions.\n",
    "    verbose : bool, optional\n",
    "        Default is False.\n",
    "        Print the progress of the sampler.\n",
    "    \"\"\"\n",
    "    # Create the figure and axes\n",
    "    fig, axes = plt.subplots(ndim + 1, 1, figsize=(10, 15));\n",
    "\n",
    "    # Run the sampler in steps and update the plot\n",
    "    i = 0\n",
    "    while i < nsteps:\n",
    "        if i == 0:\n",
    "            state = sampler.run_mcmc(initial_pos, steps_between_plot_updates, progress=verbose)\n",
    "        else:\n",
    "            state = sampler.run_mcmc(state, steps_between_plot_updates, progress=verbose)\n",
    "        update_plot(sampler, nwalkers, fig, axes)\n",
    "        i += steps_between_plot_updates\n",
    "    clear_output(wait=True)  # extra stuff to stop the notebook displaying the final plot twice\n",
    "\n",
    "    # Access the final state\n",
    "    final_state = sampler.get_last_sample().coords\n",
    "\n",
    "    return sampler, final_state\n",
    "\n",
    "# Run the sampler\n",
    "sampler.reset() # reset the sampler (you will need this if you want to run_emee fresh, from initial_pos)\n",
    "sampler, final_state = run_emcee(sampler, initial_pos, nsteps, \n",
    "                                 steps_between_plot_updates, nwalkers, ndim)\n",
    "\n",
    "# continue running  (use this if you want more steps after the first run)\n",
    "#sampler, final_state = run_emcee(sampler, final_state, nsteps, \n",
    "#                                 steps_between_plot_updates, nwalkers, ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46a3727",
   "metadata": {},
   "source": [
    "<!-- EXERCISE: BinarySourceE6.txt -->\n",
    "Depnding on the priors you chose and the random errors you generated, you may find \n",
    "that u02, tE2, or both are very poorly contrained; this would look like a large spread\n",
    "in the chains for those parameters. You could consider a prior that links the tE values\n",
    "to something similar to each other. But we may also decide to apply a prior constraint\n",
    "on the blend flux, which we reasonable know should not be negative for simulated data.\n",
    "<!-- ~~~~~~~~~~~~~~~~~~~~~~~ -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a2ce17",
   "metadata": {},
   "source": [
    "Why don't we take a look at the flux parameters for the final state and see if we can figure out what is going on?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4e5915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# corner-like scatter plot of final state: u02, t02, FS2, FB\n",
    "def plot_corner(final_state: np.ndarray, \n",
    "                model1: mm.Model, \n",
    "                model2: mm.Model, \n",
    "                data: list, \n",
    "                figure_number: Optional[int] = 3\n",
    "                ) -> None:\n",
    "    \"\"\"\n",
    "    Plot the corner-like scatter plot of the final state.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    final_state : np.ndarray\n",
    "        Array of final state parameters.\n",
    "    model1 : mm.Model\n",
    "        Primary source model.\n",
    "    model2 : mm.Model\n",
    "        Secondary source model.\n",
    "    data : list\n",
    "        List of data arrays.\n",
    "    figure_number : int, optional\n",
    "        Default is 3.\n",
    "        The figure number.\n",
    "    \"\"\"\n",
    "    # labels\n",
    "    labels = [r'$t_{0,1}$', r'$u_{0,1}$', r'$t_{E,1}$', r'$t_{0,2}$', r'$u_{0,2}$', r'$t_{E,2}$', r'$F_{S,1}$', r'$F_{S,2}$', r'$F_B$']\n",
    "\n",
    "    # collect the data dor plotting\n",
    "    corner_array = np.zeros((len(final_state), ndim + 4))\n",
    "    corner_array[:, 0:ndim] = final_state\n",
    "\n",
    "    for i in range(len(final_state)):\n",
    "        chi2, FS1, FS2, FB = binary_source_chi2(final_state[i], model1, model2, data, return_fluxes=True)\n",
    "        corner_array[i,ndim] = FS1\n",
    "        corner_array[i,ndim + 1] = FS2\n",
    "        corner_array[i,ndim + 2] = FB\n",
    "        corner_array[i,ndim + 3] = chi2\n",
    "\n",
    "    # plot\n",
    "    plt.close(figure_number)\n",
    "    plt.figure(figure_number)\n",
    "    fig, axes = plt.subplots(ndim + 3, ndim + 3, figsize=(15, 15))\n",
    "\n",
    "    for i in range(ndim+3):\n",
    "        for j in range(ndim+3):\n",
    "            if i > j:  # plot the scatter plots\n",
    "                scatter = axes[i, j].scatter(corner_array[:, j], \n",
    "                                            corner_array[:, i], \n",
    "                                            c=corner_array[:, -1], \n",
    "                                            cmap='viridis_r', \n",
    "                                            s=0.5\n",
    "                                            )\n",
    "\n",
    "                if i == ndim + 2:\n",
    "                    axes[i, j].set_xlabel(labels[j])\n",
    "                else: #turn of ticks labels\n",
    "                    axes[i, j].set_xticks([])\n",
    "\n",
    "                if j == 0:\n",
    "                    axes[i, j].set_ylabel(labels[i])\n",
    "                else: #turn of ticks labels\n",
    "                    axes[i, j].set_yticks([])\n",
    "\n",
    "            elif i == j:  # plot the histograms\n",
    "\n",
    "                axes[i, j].hist(corner_array[:, j], bins=20, color='k')\n",
    "\n",
    "                if i == ndim + 2:\n",
    "                    axes[i, j].set_xlabel(labels[j])\n",
    "                else:\n",
    "                    axes[i, j].set_xticks([])\n",
    "                \n",
    "                axes[i, j].set_yticks([])\n",
    "\n",
    "            else:  # turn off the upper triangle of axis\n",
    "                axes[i,j].axis('off')\n",
    "\n",
    "\n",
    "    # Add the colorbar using the scatter plot object\n",
    "    cbar = fig.colorbar(scatter, orientation='horizontal', ax=axes, aspect=100)\n",
    "    cbar.set_label('chi2')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_corner(final_state, model1, model2, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb7809a",
   "metadata": {},
   "source": [
    "Do you see the problem? Negative blend-flux values are allowing for overly high $F_{\\rm{S},2}$ values, in combination with correspondong low $t_{\\rm{E},2}$ and high $u_{0,2}$. We can avoid this problem by not allowing negative blending, which, considering our data was generated without using photometry, makes absolutely no sense. For events found in real data a small negative flux can be plausible as it is an indication that the \"zero flux\" background-level in the photometry was actually measuring some flux from stars. In these cases, the blend flux should actually have been measured as very small or 0. \n",
    "\n",
    "<div style=\"background-color:#e0e0e0; \n",
    "    border-left: 8px solid #808080; \n",
    "    padding: 10px 0 10px 20px; \n",
    "    margin: 20px 5px; \n",
    "    box-sizing: border-box\"> <a href=\"./Exercises/BinarySourceE7.txt\">\n",
    "    <h2 style=\"color: #808080; font-size: 24px;\">Exercise 7</h2>\n",
    "    </a>\n",
    "    <p style=\"margin: 0 20px;\">Add a prior on blend flux in <i>ln_prob()</i> function (Exercies 3) and any other additional priors you think seem reasonable.</p>\n",
    "    <br>\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color:#e0e0e0; \n",
    "    border-left: 8px solid #808080; \n",
    "    padding: 10px 0 10px 20px; \n",
    "    margin: 20px 5px; \n",
    "    box-sizing: border-box\"> <a href=\"./Exercises/BinarySourceE8.txt\">\n",
    "    <h2 style=\"color: #808080; font-size: 24px;\">Exercise 8</h2>\n",
    "    </a>\n",
    "    <p style=\"margin: 0 20px;\">Rerun the sampler and plot the results.</p>\n",
    "    <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fcad03",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "# EXERCISE: BinarySourceE8.txt PART: 1\n",
    "#---------------------\n",
    "# re make the sampler  (Make sure to run the ln_prob cell after you edit it)\n",
    "sampler = emcee.EnsembleSampler(nwalkers, ndim, ln_prob, \n",
    "                                args=[model1, model2, data])\n",
    "\n",
    "# rerun the sampler\n",
    "run_emcee(sampler, initial_pos, nsteps, steps_between_plot_updates, nwalkers, ndim)\n",
    "######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94f8d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "# EXERCISE: BinarySourceE8.txt PART: 2\n",
    "#---------------------\n",
    "# corner plot\n",
    "plot_corner(final_state, model1, model2, data)\n",
    "######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f513c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the lightcurve\n",
    "plt.close(8)\n",
    "plt.figure(8)\n",
    "\n",
    "######################\n",
    "# EXERCISE: BinarySourceE8.txt PART: 3\n",
    "#---------------------\n",
    "# Your code goes here\n",
    "\n",
    "# Plot the data\n",
    "plt.errorbar(time, flux, yerr=flux_err, \n",
    "             fmt='x', \n",
    "             ecolor='k', \n",
    "             capsize=1, \n",
    "             color='k', \n",
    "             alpha=0.6, \n",
    "             zorder=0,\n",
    "             label='simulated data'\n",
    "             )\n",
    "\n",
    "chi2_state = np.zeros(nwalkers)\n",
    "FS1_state = np.zeros(nwalkers)\n",
    "FS2_state = np.zeros(nwalkers)\n",
    "FB_state = np.zeros(nwalkers)\n",
    "for i in range(nwalkers):\n",
    "    chi2_state[i], FS1_state[i], FS2_state[i], FB_state[i] = binary_source_chi2(final_state[i], \n",
    "                                                                                model1, \n",
    "                                                                                model2, \n",
    "                                                                                data, \n",
    "                                                                                return_fluxes=True\n",
    "                                                                                )\n",
    "\n",
    "# find the minimum chi2 sample\n",
    "best = np.argmin(chi2_state)\n",
    "theta_best = final_state[best]\n",
    "print('best fit parameters:', theta_best)\n",
    "\n",
    "def plot_sample(theta, model1, model2, chi2, FS1, FS2, FB, color='k', alpha=0.1, label='_', zorder=0, ms=1):\n",
    "    \"\"\"Plot the model lightcurve\"\"\"\n",
    "    model1.parameters.t_0 = theta[0]\n",
    "    model1.parameters.u_0 = theta[1]\n",
    "    model1.parameters.t_E = theta[2]\n",
    "    model2.parameters.t_0 = theta[3]\n",
    "    model2.parameters.u_0 = theta[4]\n",
    "    model2.parameters.t_E = theta[5]\n",
    "\n",
    "    F_model = model1.get_magnification(T) * FS1 + model2.get_magnification(T) * FS2 + FB\n",
    "\n",
    "    plt.plot(T, F_model, color=color, linestyle='-', lw=1, alpha=alpha, label=label, zorder=zorder, ms=ms)\n",
    "\n",
    "# Plot the model\n",
    "for i in np.linspace(0, nwalkers-1, 10, dtype=int):\n",
    "    if i==0:\n",
    "        label = 'samples'\n",
    "    else:\n",
    "        label = '_samples'\n",
    "\n",
    "    plot_sample(final_state[i], \n",
    "                model1, \n",
    "                model2, \n",
    "                chi2_state[i], \n",
    "                FS1_state[i], \n",
    "                FS2_state[i], \n",
    "                FB_state[i], \n",
    "                color='b', \n",
    "                alpha=0.5, \n",
    "                zorder=1, \n",
    "                label=label,\n",
    "                ms=3\n",
    "                )\n",
    "    \n",
    "plot_sample(theta_best, \n",
    "            model1, \n",
    "            model2, \n",
    "            chi2_state[best], \n",
    "            FS1_state[best], \n",
    "            FS2_state[best], \n",
    "            FB_state[best], \n",
    "            color='r', \n",
    "            label='best fit', \n",
    "            zorder=2,\n",
    "            alpha=1\n",
    "            )\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.ylabel('flux')\n",
    "plt.xlabel('HJD (days)')\n",
    "######################\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f935cbf1",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#e0e0e0; \n",
    "    border-left: 8px solid #808080; \n",
    "    padding: 10px 0 10px 20px; \n",
    "    margin: 20px 5px; \n",
    "    box-sizing: border-box\"> <a href=\"./Exercises/BinarySourceE9.txt\">\n",
    "    <h2 style=\"color: #808080; font-size: 24px;\">Exercise 9</h2>\n",
    "    </a>\n",
    "    <p style=\"margin: 0 20px;\">Which of the microlensing parameters in this model show correlated posteriors?</p>\n",
    "    <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f154c1e",
   "metadata": {},
   "source": [
    "<!-- EXERCISE: BinarySourceE9.txt -->\n",
    "Depnding on the priors you chose and the random errors you generated, you may find \n",
    "that u02, tE2, or both are very poorly contrained; this would look like a large spread\n",
    "in the chains for those parameters. You could consider a prior that links the tE values\n",
    "to something similar to each other. But we may also decide to apply a prior constraint\n",
    "on the blend flux, which we reasonable know should not be negative for simulated data.\n",
    "<!-- ~~~~~~~~~~~~~~~~~~~~~~~ -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2703d43f",
   "metadata": {},
   "source": [
    "Binary source events can throw a real spanner in the works when it comes to event modelling. Binary sources complicate what is already a very complicated analysis process and the binary source model is full of correlated parameters that make it hard to determine the true values precisely. Not only can they mimic caustic purturbations with a finite source effect, but they can also mess with colour-colour inference between observatories such as contemporaneous space-based observations, or late-time follow-up lens-flux and astrometric observations. With binaries possibly making up 40% or more of the stars in the Galactic centre ([Gautam et al., 2024](https://ui.adsabs.harvard.edu/abs/2024ApJ...964..164G); [McTier, Kipping, & Johnston, 2020](https://ui.adsabs.harvard.edu/abs/2020MNRAS.495.2105M)), this potential complication is not one that should be ignored."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341f6d2a",
   "metadata": {},
   "source": [
    "Having a binary source in a microlensing event can double the number of parameters in our models, which has a dramatic impact on compute time. If we are calling a magnification function for each source, then the compute time roughly doubles for each model evaluation, as the magnification function is usually the most computationally intensive piece of microlensing event-modelling code. Besides which, higher dimensions of parameter space simply take longer to explore. \n",
    "\n",
    "These real costs are part of the reason for why microlensing simulations, to date, mostly ignore binary sources. Recent work by the PopSyCLE team ([Abrams et al., 2025](https://arxiv.org/abs/2501.03506)) found that, using their population models, 55% of observed microlensing events involve a binary system;\n",
    "* 14.5% wth a single source and muptiple lenses,\n",
    "* 31.7% with multiple sources and a single lens, and\n",
    "* 8.8% with multiple sources and multiple lenses.\n",
    "\n",
    "This paper is well worth a read, if you have the time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d52770",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#e0e0e0; \n",
    "    border-left: 8px solid #808080; \n",
    "    padding: 10px 0 10px 20px; \n",
    "    margin: 20px 5px; \n",
    "    box-sizing: border-box\"> <a href=\"./Exercises/BinarySourceE10.txt\">\n",
    "    <h2 style=\"color: #808080; font-size: 24px;\">Exercise 10</h2>\n",
    "    </a>\n",
    "    <p style=\"margin: 0 20px;\">Which binary-lens models do you think would have degenerate, binary-source, counter parts?</p>\n",
    "    <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9f8603",
   "metadata": {},
   "source": [
    "<!-- EXERCISE: BinarySourceE10.txt -->\n",
    "Binary-lens models that do not have sharp perturbations from the packzynski \n",
    "curvel; i.e., those with a large finite-source effect or without caustic \n",
    "crossings\n",
    "<!-- ~~~~~~~~~~~~~~~~~~~~~~~ -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38e23fd",
   "metadata": {},
   "source": [
    "Recent simulations by [Sangtarash & Yee (2025)](https://arxiv.org/abs/2503.11768) demonstrated that, for Roman-like cadences, the binary-source/wide-orbit-planet degeneracy is most persistent when $\\rho$ is large (which typically occurs in events with small $\\theta_{\\rm E}$) or $q$ is small, as the likelihoods of the models do not differ significantly in these cases; we can infer that, in general, lower-mass objects make this degeneracy harder to resolve."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e8fbb1",
   "metadata": {},
   "source": [
    "As a closing statement for this notebook lets simplify what we have learned to this TLDR:\n",
    "\n",
    "![Beware of the dog sign with dog replace by \"binary source\".](./Assets/beware-of-the-dog.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89923b9",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "Well, you've been warned. Now let's move on to something else. Maybe to one of these:\n",
    "+ [Binary lenses](BinaryLens.ipynb) (comming soon - see dev brach)\n",
    "+ [Higher-order effects]() (release TDB)\n",
    "+ [The Galactic model](GalacticModel.ipynb) (release TDB)\n",
    "+ [Modelling](Modelling.ipynb).\n",
    "\n",
    "Okay, bye. I'll see you there.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972176cc",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
